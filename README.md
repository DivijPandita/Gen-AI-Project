# Prompt-to-Story Generation using Transformer Models

This project demonstrates the use of Generative AI to create short, coherent stories from user-provided prompts. Built using Python, Hugging Face Transformers, and Gradio, it leverages the pre-trained GPT-2 model to produce creative narrative content in real time.

---

## ğŸš€ Features

- ğŸ“œ **Prompt-based Story Generation** using GPT-2
- ğŸ¤– Powered by **Hugging Face Transformers**
- ğŸ–¥ï¸ Interactive and clean **Gradio web interface**
- âš¡ Fast response time with creative and context-aware outputs
- ğŸ›ï¸ Adjustable sampling parameters (max length, temperature)

---

## ğŸ› ï¸ Tech Stack

- **Python 3.10+**
- **Hugging Face Transformers**
- **Gradio**
- **PyTorch**

---

## ğŸ’¡ How It Works

1. The user enters a prompt (e.g., *"I walked into the old house..."*)
2. The system sends the prompt to GPT-2 via the text-generation pipeline.
3. GPT-2 generates a short story (up to 200 tokens).
4. The story is displayed in the Gradio interface.

---

## ğŸ§ª Example

**Input Prompt:**
