# Prompt-to-Story Generation using Transformer Models

This project demonstrates the use of Generative AI to create short, coherent stories from user-provided prompts. Built using Python, Hugging Face Transformers, and Gradio, it leverages the pre-trained GPT-2 model to produce creative narrative content in real time.

---

## 🚀 Features

- 📜 **Prompt-based Story Generation** using GPT-2
- 🤖 Powered by **Hugging Face Transformers**
- 🖥️ Interactive and clean **Gradio web interface**
- ⚡ Fast response time with creative and context-aware outputs
- 🎛️ Adjustable sampling parameters (max length, temperature)

---

## 🛠️ Tech Stack

- **Python 3.10+**
- **Hugging Face Transformers**
- **Gradio**
- **PyTorch**

---

## 💡 How It Works

1. The user enters a prompt (e.g., *"I walked into the old house..."*)
2. The system sends the prompt to GPT-2 via the text-generation pipeline.
3. GPT-2 generates a short story (up to 200 tokens).
4. The story is displayed in the Gradio interface.

---

## 🧪 Example

**Input Prompt:**
